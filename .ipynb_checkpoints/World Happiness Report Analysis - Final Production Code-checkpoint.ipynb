{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The World Happiness Report Analysis\n",
    "\n",
    "##### Aly Boolani\n",
    "\n",
    "##### A written blog can be found [here](https://www.alyboolani.com/blogs/analyzing-the-worlds-happiness-report): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "\n",
    "1. **[Overview of the World Happiness Report](##Overview)**\n",
    "    * [Context](##)\n",
    "    * [Data Acknowledgment](##)\n",
    "    \n",
    "    \n",
    "2. **[Importing Python Packages](#Imports)**\n",
    "\n",
    "\n",
    "3. **[First look at the Data](##)**\n",
    "     * [Individual DataFrames](##)\n",
    "     * [Data Description, Information & Data Types]\n",
    "     * [Nulls & Missing Values](##)\n",
    "     * [Early Observations](##)\n",
    "\n",
    "\n",
    "4. **[Feature Engineering](##)**\n",
    "    * [Aligning the DataFrames](##)\n",
    "        * [Renaming columns](##)\n",
    "        * [Adding columns](##)\n",
    "        \n",
    "    * [Combining the DataFrames](##)\n",
    "    * [Additions to DataFrame](##)\n",
    "        * [Capital Cities](##)\n",
    "        * [Capital Latitude & Longitude](##)\n",
    "  \n",
    "    \n",
    "5. **[Insights & Findings](##)**\n",
    "    * [World Map Visualization](##)\n",
    "       \n",
    "    * [Top 10 happiest countries overall](##)\n",
    "        * [2020](##)\n",
    "        * [2019](##)\n",
    "        * [2018](##)\n",
    "        * [2017](##)\n",
    "        * [2016](##)\n",
    "        * [2015](##)\n",
    "    * [Least 10 happiest countries overall](##)\n",
    "        * [2020](##)\n",
    "        * [2019](##)\n",
    "        * [2018](##)\n",
    "        * [2017](##)\n",
    "        * [2016](##)\n",
    "        * [2015](##)\n",
    "        \n",
    "        \n",
    "6. **[Scatter plots - Relationship between Happiness Score and:](##)**\n",
    "    * [Region - encoded](##)\n",
    "    * [GDP Per Capita](##)\n",
    "    * [Social Support](##)\n",
    "    * [Health / Life Expectancy](##)\n",
    "    * [Freedom to make choices](##)\n",
    "    * [Family Safety](##)\n",
    "    * [Trust in Government Entities](##)\n",
    "    * [Generosity](##)\n",
    "    * [Dystopia Residual](##) \n",
    "        \n",
    "\n",
    "7. **[Using Machine Learning to understand major influencing factors](##)**\n",
    "    * [Linear Regression](##)\n",
    "    * [Logistic Regression](##)\n",
    "    * [Support Vector Machines - Regressor](##)\n",
    "    * [Scalers](##)\n",
    "        * [Standard Scaler](##)\n",
    "        * [Min-Max Scaler](##)\n",
    "    * [Principal Component Analysis (PCA)](##)\n",
    "    * [Grid Search with Cross Validation](##)\n",
    "    \n",
    "\n",
    "8. **[Final Verdict](##)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Overview of the World Happiness Report! \n",
    "---\n",
    "The **World Happiness Report** may be a point of interest survey of the state of worldwide bliss. The primary report was distributed in 2012, the second in 2013, third in 2015, and the fourth with the 2016 upgrade. **The World Joy 2017**, which positions 155 nations by their bliss levels, was discharged at the Joined together Countries at an occasion celebrating Universal Day of Joy. The report proceeds to pick up worldwide acknowledgment as governments, organizations and respectful society progressively utilize joy pointers to educate their policy-making choices. Driving specialists over areas – financial matters, brain research, overview investigation, national insights, wellbeing, open approach and more – depict how estimations of well-being can be used effectively to evaluate the advance of countries. The reports survey the state of bliss within the world nowadays and appear how the modern science of bliss clarifies individual and national varieties in bliss. \n",
    "\n",
    "The joy scores and rankings utilize information from the Gallup World Survey. The scores are based on answers to the most life evaluation address inquired within the survey. This address, known as the Cantril step, asks respondents to think of a step with the most excellent conceivable life for them being a 10 and the most exceedingly bad conceivable life being a and to rate their claim current lives on that scale. The scores are from broadly agent tests for the a long time 2013-2016 and utilize the Gallup weights to create the gauges agent. The columns taking after the bliss score assess the degree to which each of six variables – financial generation, social back, life anticipation, flexibility, nonattendance of debasement, and liberality – contribute to making life assessments higher in each nation than they are in Dystopia, a theoretical nation that has values rise to to the world’s least national midpoints for each of the six variables. They have no affect on the full score detailed for each nation, but they do explain the variance.\n",
    "\n",
    "The files contains the Happiness Score for 153 countries along with the factors used to explain the score from the year 2015 to 2020.\n",
    "\n",
    "Lastly, **The Happiness Score** is a national average of the responses to the main life evaluation question asked in the Gallup World Poll (GWP), which uses the Cantril Ladder. It can be explained by the following factors:\n",
    "- Access to Social Support\n",
    "- Economy (GDP per Capita)\n",
    "- Family\n",
    "- Health / Life Expectancy\n",
    "- Freedom to make choices\n",
    "- Trust in Government Entities\n",
    "- Generosity\n",
    "- Dystopia Residual\n",
    "\n",
    "\n",
    "### Data Acknowlegment\n",
    "Before we begin, I want to quickly acknowledge that the data has been sourced from Kaggle and can be found [here](https://www.kaggle.com/mathurinache/world-happiness-report). The original authors & editors are: \n",
    "\n",
    "**Editors:** \n",
    "\n",
    "John Helliwell, Richard Layard, Jeffrey D. Sachs, and Jan Emmanuel De Neve, Co-Editors; Lara Aknin, Haifang Huang and Shun Wang, Associate Editors; and Sharon Paculor, Production Editor\n",
    "\n",
    "**Citation:**\n",
    "\n",
    "Helliwell, John F., Richard Layard, Jeffrey Sachs, and Jan-Emmanuel De Neve, eds. 2020. World Happiness Report 2020. New York: Sustainable Development Solutions Network\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the packages\n",
    "# Analysis Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization Libraries\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing plotly objects\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# For sounds when code blocks complete\n",
    "import os\n",
    "\n",
    "# For saving the models later. \n",
    "import joblib\n",
    "\n",
    "# Displaying DataFrames - side by side function \n",
    "from IPython.display import display_html\n",
    "\n",
    "# GeoPy Package - Extensions for getting country latitude and longitudes (pip install GeoPy)\n",
    "from geopy.exc import GeocoderTimedOut \n",
    "from geopy.geocoders import Nominatim \n",
    "\n",
    "# For making training and testing splits prior to modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing Scaler for Scaling Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Machine Learning Imports \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "# For building up a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For a cross-validated grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Stopping warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# First look at the Data\n",
    "---\n",
    "This will include taking a look at the following:\n",
    "- Individual DataFrames\n",
    "- Data Description, Information & Data Types\n",
    "- Nulls & Missing Values\n",
    "- Early Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in our data and setting dataframes to a variable\n",
    "Year_2015 = pd.read_csv('2015.csv')\n",
    "Year_2016 = pd.read_csv('2016.csv')\n",
    "Year_2017 = pd.read_csv('2017.csv')\n",
    "Year_2018 = pd.read_csv('2018.csv')\n",
    "Year_2019 = pd.read_csv('2019.csv')\n",
    "Year_2020 = pd.read_csv('2020.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual DataFrames - First 5 and last 5 rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the dataframe for the year 2015\n",
    "Year_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the dataframe for the year 2016\n",
    "Year_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the dataframe for the year 2017\n",
    "Year_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the dataframe for the year 2018\n",
    "Year_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the dataframe for the year 2019\n",
    "Year_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the dataframe for the year 2020\n",
    "Year_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Description, Information & Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of DataFrame = Year 2015 \n",
    "Year_2015.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of DataFrame = Year 2015 \n",
    "Year_2016.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of DataFrame = Year 2015 \n",
    "Year_2017.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of DataFrame = Year 2015 \n",
    "Year_2018.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of DataFrame = Year 2015 \n",
    "Year_2019.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of DataFrame = Year 2015 \n",
    "Year_2020.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-4-e82032ec469b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-e82032ec469b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print(f\"Countries in 2016: {len(Year_2016)} & unique countries are: {Year_2016['Country'].nunique()}\")\")\u001b[0m\n\u001b[0m                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Printing out the countries but also the unique countries incase repetition\n",
    "print(f\"Countries in 2015: {len(Year_2015)} & unique countries are: {Year_2015['Country'].nunique()}\")\n",
    "print(f\"Countries in 2016: {len(Year_2016)} & unique countries are: {Year_2016['Country'].nunique()}\")\n",
    "print(f\"Countries in 2017: {len(Year_2017)} & unique countries are: {Year_2017['Country'].nunique()}\")\n",
    "print(f\"Countries in 2018: {len(Year_2018)} & unique countries are: {Year_2018['Country'].nunique()}\")\n",
    "print(f\"Countries in 2019: {len(Year_2019)} & unique countries are: {Year_2019['Country'].nunique()}\")\n",
    "print(f\"Countries in 2020: {len(Year_2020)} & unique countries are: {Year_2020['Country'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the number of duplicates\n",
    "print(f\"Year 2015 duplicates: {Year_2015.duplicated().sum()}\")\n",
    "print(f\"Year 2016 duplicates: {Year_2016.duplicated().sum()}\")\n",
    "print(f\"Year 2017 duplicates: {Year_2017.duplicated().sum()}\")\n",
    "print(f\"Year 2018 duplicates: {Year_2018.duplicated().sum()}\")\n",
    "print(f\"Year 2019 duplicates: {Year_2019.duplicated().sum()}\")\n",
    "print(f\"Year 2020 duplicates: {Year_2020.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nulls & Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Year_2015' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-84228efb8547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Printing out the number of duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Year 2015 null values: {len(Year_2015.isnull().sum())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Year 2016 null values: {len(Year_2016.isnull().sum())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Year 2017 null values: {len(Year_2017.isnull().sum())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Year 2018 null values: {len(Year_2018.isnull().sum())}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Year_2015' is not defined"
     ]
    }
   ],
   "source": [
    "# Printing out the number of Nulls\n",
    "print(f\"Year 2015 null values: {len(Year_2015.isnull().sum())}\")\n",
    "print(f\"Year 2016 null values: {len(Year_2016.isnull().sum())}\")\n",
    "print(f\"Year 2017 null values: {len(Year_2017.isnull().sum())}\")\n",
    "print(f\"Year 2018 null values: {len(Year_2018.isnull().sum())}\")\n",
    "print(f\"Year 2019 null values: {len(Year_2019.isnull().sum())}\")\n",
    "print(f\"Year 2020 null values: {len(Year_2020.isnull().sum())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick Visualizations while we explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the top 20 countries of 2020 listed as the most happiest\n",
    "plt.figure()\n",
    "plt.plot(data = (Year_2020['Country','Happiness Score'].sort_values(by ='Happiness Score').head()),\n",
    "         kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature Engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aligning the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the shape of our dataframes\n",
    "print(f\"World Happiness Report 2015: {Year_2015.shape}\")\n",
    "print(f\"World Happiness Report 2016: {Year_2016.shape}\")\n",
    "print(f\"World Happiness Report 2017: {Year_2017.shape}\")\n",
    "print(f\"World Happiness Report 2018: {Year_2018.shape}\")\n",
    "print(f\"World Happiness Report 2019: {Year_2019.shape}\")\n",
    "print(f\"World Happiness Report 2020: {Year_2020.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding columns\n",
    "\n",
    "1. Report Year\n",
    "2. Country Capitals\n",
    "3. Latitude & Longitude\n",
    "4. Happiness Brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Report Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a first column to the 2015 DataFrame with value 2015\n",
    "Year_2015.insert(0 , column = 'Report Year', value = '2015')\n",
    "\n",
    "# Adding a first column to the 2016 DataFrame with value 2016\n",
    "Year_2016.insert(0 , column = 'Report Year', value = '2016')\n",
    "\n",
    "# Adding a first column to the 2017 DataFrame with value 2017\n",
    "Year_2017.insert(0 , column = 'Report Year', value = '2017')\n",
    "\n",
    "# Adding a first column to the 2018 DataFrame with value 2018\n",
    "Year_2018.insert(0 , column = 'Report Year', value = '2018')\n",
    "\n",
    "# Adding a first column to the 2019 DataFrame with value 2019\n",
    "Year_2019.insert(0 , column = 'Report Year', value = '2019')\n",
    "\n",
    "# Adding a first column to the 2020 DataFrame with value 2020\n",
    "Year_2020.insert(0 , column = 'Report Year', value = '2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Country Capitals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Reading in a new dataframe with country names and capital cities\n",
    "country_capitals = pd.read_csv('Country list.csv')\n",
    "country_capitals.rename(columns = {'Countries' : 'Country'}, inplace = True)\n",
    "country_capitals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Latitude & Longitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty list to store latitudes and longitudes of cities\n",
    "longitude = [] \n",
    "latitude = [] \n",
    "   \n",
    "# Creating a function to find coordinators of a given city\n",
    "def findGeocode(city): \n",
    "       \n",
    "    # Try & catch will be used to ovecome exceptions thrown by \n",
    "    # geolocator using geocodertimedout \n",
    "    try: \n",
    "          \n",
    "        # Specify the user agent as 'your_app_name', shouldn't be empty\n",
    "        geolocator = Nominatim(user_agent=\"your_app_name\") \n",
    "        \n",
    "        # locates the city locator\n",
    "        return geolocator.geocode(city) \n",
    "      \n",
    "    except GeocoderTimedOut: \n",
    "          \n",
    "        # locates the city    \n",
    "        return findGeocode(city)     \n",
    "  \n",
    "# Each value from city column will be fethced and send to function find_geocode\n",
    "\n",
    "# Creating a for loop where it goes rows by rows and fetches lat/long per city\n",
    "for city in country_capitals['Capital']: \n",
    "      \n",
    "    if findGeocode(i) != None: \n",
    "           \n",
    "        loc = findGeocode(i) \n",
    "          \n",
    "        # Coordinators get returned from the function and is stored in two lists \n",
    "        latitude.append(loc.latitude) \n",
    "        longitude.append(loc.longitude) \n",
    "       \n",
    "    # if coordinate for a city not \n",
    "    # found, insert \"NaN\" indicating  \n",
    "    # missing value  \n",
    "    else: \n",
    "        latitude.append(np.nan) \n",
    "        longitude.append(np.nan) \n",
    "        \n",
    "# Let's finally put these into the country_capitals dataframe\n",
    "country_capitals['Latitude'] = latitude\n",
    "country_capitals['Longitude'] = longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's quickly take a look at the new dataframe \n",
    "country_capitals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also take a look to see if there are any nulls within these\n",
    "print(f\"Null values in Country_Capitals: {len(country_capitals.isnull().sum())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning up the dataframes before moving on to combining them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the columns for Year 2015\n",
    "# Renaming the columns and grouping together \n",
    "clean_2015 = {'Country' : 'Country', 'Region' : 'Region', 'Happiness Rank' : 'Happiness Rank',\n",
    "              'Happiness Score' : 'Happiness Score', 'Economy (GDP per Capita)' : 'Economy (GDP per Capita)',\n",
    "              'Family' : 'Family Safety','Health (Life Expectancy)' : 'Health / Life Expectancy',\n",
    "              'Freedom' : 'Freedom to make choices',\n",
    "              'Trust (Government Corruption)' : 'Trust in Government Entities',\n",
    "              'Generosity' : 'Generosity', 'Dystopia Residual' : 'Dystopia Residual'}\n",
    "\n",
    "clean_2016 = {'Country' : 'Country', 'Region' : 'Region', 'Happiness Rank' : 'Happiness Rank',\n",
    "              'Happiness Score' : 'Happiness Score', 'Economy (GDP per Capita)' : 'Economy (GDP per Capita)',\n",
    "              'Family' : 'Family Safety','Health (Life Expectancy)' : 'Health / Life Expectancy',\n",
    "              'Freedom' : 'Freedom to make choices',\n",
    "              'Trust (Government Corruption)' : 'Trust in Government Entities',\n",
    "              'Generosity' : 'Generosity', 'Dystopia Residual' : 'Dystopia Residual'}\n",
    "\n",
    "clean_2017 = {'Country' : 'Country', 'Region' : 'Region', 'Happiness.Rank' : 'Happiness Rank',\n",
    "              'Happiness.Score' : 'Happiness Score', 'Economy..GDP.per.Capita.' : 'Economy (GDP per Capita)',\n",
    "              'Family' : 'Family Safety','Health..Life.Expectancy.' : 'Health / Life Expectancy',\n",
    "              'Freedom' : 'Freedom to make choices',\n",
    "              'Trust..Government.Corruption.' : 'Trust in Government Entities',\n",
    "              'Generosity' : 'Generosity', 'Dystopia.Residual' : 'Dystopia Residual'}\n",
    "\n",
    "clean_2018 = {'Country or region' : 'Country', 'Overall rank' : 'Happiness Rank', 'Social support' : 'Social Support',\n",
    "              'Score' : 'Happiness Score', 'GDP per capita' : 'Economy (GDP per Capita)',\n",
    "              'Family' : 'Family Safety','Healthy life expectancy' : 'Health / Life Expectancy',\n",
    "              'Freedom to make life choices' : 'Freedom to make choices',\n",
    "              'Perceptions of corruption' : 'Trust in Government Entities',\n",
    "              'Generosity' : 'Generosity', 'Dystopia Residual' : 'Dystopia Residual'}\n",
    "\n",
    "clean_2019 = {'Country or region' : 'Country', 'Overall rank' : 'Happiness Rank', 'Social support' : 'Social Support',\n",
    "              'Score' : 'Happiness Score', 'GDP per capita' : 'Economy (GDP per Capita)',\n",
    "              'Family' : 'Family Safety','Healthy life expectancy' : 'Health / Life Expectancy',\n",
    "              'Freedom to make life choices' : 'Freedom to make choices',\n",
    "              'Perceptions of corruption' : 'Trust in Government Entities',\n",
    "              'Generosity' : 'Generosity', 'Dystopia Residual' : 'Dystopia Residual'}\n",
    "\n",
    "clean_2020 = {'Country' : 'Country', 'Regional indicator' : 'Region', 'Happiness Rank' : 'Happiness Rank',\n",
    "              'Ladder score' : 'Happiness Score', 'Economy (GDP per Capita)' : 'Economy (GDP per Capita)',\n",
    "              'Family' : 'Family Safety','Healthy life expectancy' : 'Health / Life Expectancy',\n",
    "              'Freedom to make life choices' : 'Freedom to make choices', 'Social support' : 'Social Support',\n",
    "              'Perceptions of corruption' : 'Trust in Government Entities',\n",
    "              'Generosity' : 'Generosity', 'Dystopia Residual' : 'Dystopia Residual'}\n",
    "\n",
    "\n",
    "# Assigning the new column names to ensurie they align \n",
    "Year_2015.rename(columns = clean_2015, inplace = True)\n",
    "Year_2016.rename(columns = clean_2016, inplace = True)\n",
    "Year_2017.rename(columns = clean_2017, inplace = True)\n",
    "Year_2018.rename(columns = clean_2018, inplace = True)\n",
    "Year_2019.rename(columns = clean_2019, inplace = True)\n",
    "Year_2020.rename(columns = clean_2020, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Happiness Ranks and Happiness Scores for 2015\n",
    "Average_Happiness_Rank_Scores_2015 = Year_2015[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2015.rename({'Happiness Rank' : 'Happiness Rank_2015',\n",
    "                                      'Happiness Score': 'Happiness Score_2015'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2016\n",
    "Average_Happiness_Rank_Scores_2016 = Year_2016[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2016.rename({'Happiness Rank' : 'Happiness Rank_2016',\n",
    "                                      'Happiness Score': 'Happiness Score_2016'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2017\n",
    "Average_Happiness_Rank_Scores_2017 = Year_2017[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2017.rename({'Happiness Rank' : 'Happiness Rank_2017',\n",
    "                                      'Happiness Score': 'Happiness Score_2017'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2018\n",
    "Average_Happiness_Rank_Scores_2018 = Year_2018[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2018.rename({'Happiness Rank' : 'Happiness Rank_2018',\n",
    "                                      'Happiness Score': 'Happiness Score_2018'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2019\n",
    "Average_Happiness_Rank_Scores_2019 = Year_2019[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2019.rename({'Happiness Rank' : 'Happiness Rank_2019',\n",
    "                                      'Happiness Score': 'Happiness Score_2019'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2020\n",
    "Average_Happiness_Rank_Scores_2020 = Year_2020[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2020.rename({'Happiness Rank' : 'Happiness Rank_2020',\n",
    "                                      'Happiness Score': 'Happiness Score_2020'}, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the average scores across all countries\n",
    "print('Average Happiness Score across all countries are:\n",
    "      .mean()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to get the sum of all happiness score and divde that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Happiness Bracket and Average Happiness**\n",
    "\n",
    "This will help us see the distribution of happiness in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting subplots for seeing happiness distribution each year \n",
    "Happiness_Ranks = []\n",
    "Happiness_Scores = [Happiness Score_2020, \n",
    "                    Happiness Score_2019, \n",
    "                    Happiness Score_2018,\n",
    "                    Happiness Score_2017,\n",
    "                    Happiness Score_2016,\n",
    "                    Happiness Score_2015]\n",
    "\n",
    "plt.subplots(figsize = (10,10),\n",
    "             nrows = 4,\n",
    "             ncols = 2)\n",
    "\n",
    "plt.subplot()\n",
    "plt.title()\n",
    "plt.xlabel()\n",
    "plt.ylabel()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting subplots for these to understand relationship between happiness score and he rest \n",
    "plt.subplots(figsize = (20,20), \n",
    "             nrows = 4, \n",
    "             ncols = 2)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Economy (GDP per Capita)\n",
    "plt.subplot(4,2,1)\n",
    "sns.regplot(x = Year_2015['Happiness Score'], \n",
    "            y = Year_2015['Economy (GDP per Capita)'],\n",
    "            color = 'red', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Economy (GDP per Capita)')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Social Support\n",
    "plt.subplot(4,2,2)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Social Support'],\n",
    "            color = 'green', marker = 'o')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Social Support')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Health / Life Expectancy\n",
    "plt.subplot(4,2,3)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Health / Life Expectancy'],\n",
    "            color = 'blue', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Health / Life Expectancy')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Freedom to make choices\n",
    "plt.subplot(4,2,4)\n",
    "sns.regplot(x = Year_2015['Happiness Score'], \n",
    "            y = Year_2015['Freedom to make choices'],\n",
    "            color = 'orange', marker = 'o')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Freedom to make choices')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Family Safety\n",
    "plt.subplot(4,2,5)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Family Safety'],\n",
    "            color = 'red', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Family Safety')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Trust in Government Entities\n",
    "plt.subplot(4,2,6)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Trust in Government Entities'],\n",
    "            color = 'green', marker = 'o')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Trust in Government Entities')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Generosity\n",
    "plt.subplot(4,2,7)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Generosity'],\n",
    "            color = 'green', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Generosity')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Dystopia Residual\n",
    "plt.subplot(4,2,8)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Dystopia Residual'],\n",
    "            color = 'green', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Dystopia Residual')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining our dataframe altogether"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before we move onto putting the dataframes together, let's ensure it looks like as follows:**\n",
    "\n",
    "- `Country`\n",
    "- `Region`\n",
    "- `Capital`\n",
    "- `Latitude`\n",
    "- `Longitude`\n",
    "- `Average Happiness Score (2015-2020)`\n",
    "\n",
    "\n",
    "- Happiness Ranks as follows:\n",
    "    - `Happiness Rank_2020`\n",
    "    - `Happiness Rank_2019`\n",
    "    - `Happiness Rank_2018`\n",
    "    - `Happiness Rank_2017`\n",
    "    - `Happiness Rank_2016`\n",
    "    - `Happiness Rank_2015`\n",
    "    \n",
    "    \n",
    "- Happiness Scores as follows:\n",
    "    - `Happiness Score_2020`\n",
    "    - `Happiness Score_2019`\n",
    "    - `Happiness Score_2018`\n",
    "    - `Happiness Score_2017`\n",
    "    - `Happiness Score_2016`\n",
    "    - `Happiness Score_2015`\n",
    "    \n",
    "\n",
    "- `Economy (GDP per Capita)`\n",
    "- `Social Support`\n",
    "- `Health / Life Expectancy`\n",
    "- `Freedom to make choices`\n",
    "- `Trust in Government Entities`\n",
    "- `Generosity`\n",
    "- `Dystopia Residual`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Happiness Ranks and Happiness Scores for 2015\n",
    "Average_Happiness_Rank_Scores_2015 = Year_2015[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2015.rename({'Happiness Rank' : 'Happiness Rank_2015',\n",
    "                                      'Happiness Score': 'Happiness Score_2015'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2016\n",
    "Average_Happiness_Rank_Scores_2016 = Year_2016[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2016.rename({'Happiness Rank' : 'Happiness Rank_2016',\n",
    "                                      'Happiness Score': 'Happiness Score_2016'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2017\n",
    "Average_Happiness_Rank_Scores_2017 = Year_2017[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2017.rename({'Happiness Rank' : 'Happiness Rank_2017',\n",
    "                                      'Happiness Score': 'Happiness Score_2017'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2018\n",
    "Average_Happiness_Rank_Scores_2018 = Year_2018[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2018.rename({'Happiness Rank' : 'Happiness Rank_2018',\n",
    "                                      'Happiness Score': 'Happiness Score_2018'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2019\n",
    "Average_Happiness_Rank_Scores_2019 = Year_2019[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2019.rename({'Happiness Rank' : 'Happiness Rank_2019',\n",
    "                                      'Happiness Score': 'Happiness Score_2019'}, axis = 1, inplace = True)\n",
    "\n",
    "# Adding the Happiness Ranks and Happiness Scores for 2020\n",
    "Average_Happiness_Rank_Scores_2020 = Year_2020[['Country', 'Happiness Rank', 'Happiness Score']]\n",
    "Average_Happiness_Rank_Scores_2020.rename({'Happiness Rank' : 'Happiness Rank_2020',\n",
    "                                      'Happiness Score': 'Happiness Score_2020'}, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code WILL CHANGE\n",
    "#Creating a DataFrame for \n",
    "combined_df = pd.DataFrame(columns = ['Country', 'Capital', 'Region', 'Latitude', 'Longitude', \n",
    "                                      'Happiness Rank_2015', 'Happiness Score_2015', 'Average Happiness Score (2015-2020)', \n",
    "                                      'Happiness Rank_2016', 'Happiness Score_2016',\n",
    "                                      'Happiness Rank_2017', 'Happiness Score_2017',\n",
    "                                      'Happiness Rank_2018', 'Happiness Score_2018',\n",
    "                                      'Happiness Rank_2019', 'Happiness Score_2019',\n",
    "                                      'Happiness Rank_2020', 'Happiness Score_2020',\n",
    "                                      'Standard Error', 'Social Support', 'Lower Confidence Interval', \n",
    "                                      'Upper Confidence Interval', 'Upper Whisker','Lower Whisker', \n",
    "                                      'Economy (GDP per Capita)', 'Family', 'Health / Life Expectancy', \n",
    "                                      'Freedom to make choices', 'Trust in Government Entities', 'Generosity', \n",
    "                                      'Dystopia Residual'])\n",
    "\n",
    "dataframes = [Year_2015, Year_2016, Year_2017, Year_2018, Year_2019, Year_2020]\n",
    "\n",
    "for data in dataframes:\n",
    "    combined_df = combined_df.append(data[['Country', 'Region', 'Capital', 'Happiness Score', 'Economy (GDP per Capita)', \n",
    "                                           'Health (Life Expectancy)']], ignore_index = 'True')\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Insights & Findings\n",
    "---\n",
    "This will include the following: \n",
    "- World Map Visualization\n",
    "- Top 10 happiest countries overall\n",
    "- Least 10 happiest countries overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### World Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing plotly objects\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Setting up the dataframe \n",
    "df = country_capitals\n",
    "df['Visualization Content'] = df['Capital'] + ', ' \n",
    "                                + df['Country'] + ', ' \n",
    "                                + df['Happiness Score']\n",
    "\n",
    "\n",
    "# Setting up the figure\n",
    "fig = go.Figure(data = go.Scatter(\n",
    "        lon = df['Longitude'],\n",
    "        lat = df['Latitude'],\n",
    "        text = df['Visualization Content'],\n",
    "        mode = 'markers'\n",
    "        marker = dict(\n",
    "            size = 8,\n",
    "            opacity = 0.5,\n",
    "            reversescale = True,\n",
    "            line = dict(\n",
    "                width = 1, \n",
    "                color = 'rgba(102,102,102)'\n",
    "            ),\n",
    "            colorscale = 'Blues',\n",
    "            cmin = 0,\n",
    "            cmax = 10,\n",
    "            colorbar_title = 'Happiness Score'\n",
    "        )))\n",
    "\n",
    "# Updating the figure\n",
    "fig.update_layout(width = 1000,\n",
    "                  height = 1000,\n",
    "                  title_text = 'World Happiness Map',\n",
    "                  title_font_size = 30,\n",
    "                  xaxis_title = '', yaxis_title = ''\n",
    ")\n",
    "                           \n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to display dataframes side by side**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function\n",
    "def display_side_by_side(*args):\n",
    "    \"\"\"\n",
    "    This function takes the two dataframes and puts them side by side and should be put in a format as follows:\n",
    "    side_to_side(dataframe 1, dataframe 2)\n",
    "    \"\"\"\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall & Year-by-Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top 10 happiest countries overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the 10 happiest countries in the past 6 years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Least 10 happiest countries overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the 10 least happiest countries in the past 6 years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 happiest & least happiest countries in 2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 happiest countries in 2020\n",
    "Top_10_2020 = pd.DataFrame(Year_2020[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).head(10))\n",
    "\n",
    "# Top 10 least happiest countries in 2020\n",
    "Bottom_10_2020 = pd.DataFrame(Year_2020[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).tail(10))\n",
    "\n",
    "# Showing the DataFrame side by side\n",
    "display_side_by_side(Top_10_2020, Bottom_10_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 happiest & least happiest countries in 2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 happiest countries in 2019\n",
    "Top_10_2019 = pd.DataFrame(Year_2019[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).head(10))\n",
    "\n",
    "# Top 10 least happiest countries in 2019\n",
    "Bottom_10_2019 = pd.DataFrame(Year_2019[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).tail(10))\n",
    "\n",
    "# Showing the DataFrame side by side\n",
    "display_side_by_side(Top_10_2019, Bottom_10_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 happiest & least happiest countries in 2018**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 happiest countries in 2018\n",
    "Top_10_2018 = pd.DataFrame(Year_2018[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).head(10))\n",
    "# Top 10 least happiest countries in 2018\n",
    "Bottom_10_2018 = pd.DataFrame(Year_2018[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).tail(10))\n",
    "\n",
    "# Showing the DataFrame side by side\n",
    "display_side_by_side(Top_10_2018, Bottom_10_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 happiest & least happiest countries in 2017**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_10_2017 = pd.DataFrame(Year_2017[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).head(10))\n",
    "Bottom_10_2017 = pd.DataFrame(Year_2017[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).tail(10))\n",
    "\n",
    "display_side_by_side(Top_10_2017, Bottom_10_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 happiest & least happiest countries in 2016**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_10_2016 = pd.DataFrame(Year_2016[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).head(10))\n",
    "Bottom_10_2016 = pd.DataFrame(Year_2016[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).tail(10))\n",
    "\n",
    "display_side_by_side(Top_10_2016, Bottom_10_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 10 happiest & least happiest countries in 2015**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bottom_10_2015 = pd.DataFrame(Year_2015[['Country', \n",
    "                                      'Happiness Score', \n",
    "                                      'Happiness Rank']].sort_values(by = 'Happiness Rank',\n",
    "                                                                     ascending = True).tail(10))\n",
    "\n",
    "display_side_by_side(Top_10_2015, Bottom_10_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scatter Plots - Understanding the Relationships\n",
    "---\n",
    "This will include scatterplots for the following comparing Happiness Score with:\n",
    "- Economy (GDP per Capita)\n",
    "- Social Support\n",
    "- Health / Life Expectancy\n",
    "- Freedom to make choices\n",
    "- Family Safety\n",
    "- Trust in Government Entities\n",
    "- Generosity\n",
    "- Dystopia Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting subplots for these to understand relationship between happiness score and he rest \n",
    "plt.subplots(figsize = (20,20), \n",
    "             nrows = 4, \n",
    "             ncols = 2)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Economy (GDP per Capita)\n",
    "plt.subplot(4,2,1)\n",
    "sns.regplot(x = Year_2015['Happiness Score'], \n",
    "            y = Year_2015['Economy (GDP per Capita)'],\n",
    "            color = 'red', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Economy (GDP per Capita)')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Social Support\n",
    "plt.subplot(4,2,2)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Social Support'],\n",
    "            color = 'green', marker = 'o')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Social Support')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Health / Life Expectancy\n",
    "plt.subplot(4,2,3)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Health / Life Expectancy'],\n",
    "            color = 'blue', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Health / Life Expectancy')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Freedom to make choices\n",
    "plt.subplot(4,2,4)\n",
    "sns.regplot(x = Year_2015['Happiness Score'], \n",
    "            y = Year_2015['Freedom to make choices'],\n",
    "            color = 'orange', marker = 'o')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Freedom to make choices')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Family Safety\n",
    "plt.subplot(4,2,5)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Family Safety'],\n",
    "            color = 'red', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Family Safety')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Trust in Government Entities\n",
    "plt.subplot(4,2,6)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Trust in Government Entities'],\n",
    "            color = 'green', marker = 'o')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Trust in Government Entities')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Generosity\n",
    "plt.subplot(4,2,7)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Generosity'],\n",
    "            color = 'green', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Generosity')\n",
    "plt.xlim(0,10)\n",
    "\n",
    "# Scatter subplot for Happiness Score & Dystopia Residual\n",
    "plt.subplot(4,2,8)\n",
    "sns.regplot(x = Year_2015['Happiness Score'],\n",
    "            y = Year_2015['Dystopia Residual'],\n",
    "            color = 'green', marker = '*')\n",
    "plt.title('')\n",
    "plt.xlabel('Happiness Score')\n",
    "plt.ylabel('Dystopia Residual')\n",
    "plt.xlim(0,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Using Machine Learning to better understand the major influencing factors affecting World Happiness! \n",
    "---\n",
    "This will include ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled & Unscaled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Min-Max Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Modeling\n",
    "---\n",
    "\n",
    "Regression analysis estimates the relationship between two or more variables. There are multiple benefits of using regression analysis and are as follows:\n",
    "- It indicates the **significant relationships** between dependent variable and independent variable.\n",
    "- It indicates the **strength of impact** of multiple independent variables on a dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate the model\n",
    "LinR_model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "LinR_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "LinR_model.score(X_test, y_test)\n",
    "\n",
    "# Print extra reports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a7cdf20f23dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instatiate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLinR_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLinR_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Instatiate the model\n",
    "LinR_model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "LinR_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Test the model\n",
    "LinR_model.score(X_test, y_test)\n",
    "\n",
    "# Print extra reports "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate the model\n",
    "LogR_model = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "LogR_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "LogR_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression model can handle various types of relationship and is most widely used for classification problems. This is because it applies a non-linear log transofrmation to the predicted odds ratio. \n",
    "\n",
    "What we must keep in mind is that the independent variables should not be correlated with each other i.e. no multi collinearity. Therefore, this fails are model findings because it could be argued that many of the variables are inter-related!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate the model\n",
    "SVM_model = LinearSVR()\n",
    "\n",
    "# Fit the model\n",
    "SVM_model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "LogR_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search with Cross Validation\n",
    "\n",
    "Steps for setting up a Grid Search with Cross Validation are as follows:\n",
    "- Split the Data into training and testing sets \n",
    "- Print out the shape of the data sets\n",
    "- Instantiate Pipeline with the proper steps & parameters\n",
    "- Setting up the `param_grid` before moving on to the Grid Search\n",
    "- Finally, instantiate the Grid Search with the cross validations & fit on training set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Split the Data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data again into features and target variables\n",
    "X = dataframe['']\n",
    "y = dataframe['Average Happiness Score (2015-2020)']\n",
    "                \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    stratify = y, \n",
    "                                                    random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Printing the shape of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some print statements to see what the data looks like prior to splitting\n",
    "print('Total Data Set Size')\n",
    "print(f\"Shape of our features predicting happiness: {X.shape}\")\n",
    "print(f\"Shape of our target variable predicting happiness: {y.shape}\")\n",
    "\n",
    "# Some print statements to see what the training data looks like\n",
    "print('Training set size:')\n",
    "print(f\"Features shape: {X_train.shape}\")\n",
    "print(f\"Target shape: {y_train.shape}\")\n",
    "\n",
    "# Some print statements to see what the testing data looks like\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Instantiating and setting up our pipeline parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our pipeline to scale the data and apply modeling\n",
    "pipeline = Pipeline([('Scaler', StandardScaler()),\n",
    "                     ('model', LinearRegression())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Setting up the `param_grid` before moving on to the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we create a list of parametres we will be using for our GridSearchCV\n",
    "scalers = [None, MinMaxScaler(), StandardScaler()]\n",
    "\n",
    "n_jobs = -1\n",
    "\n",
    "# Parameters for Linear Regression\n",
    "param_grid_LinR = {'scaler' : scalers, \n",
    "                   'model' : [LinearRegression()], \n",
    "                   'model__n_jobs': n_jobs}\n",
    "\n",
    "# Parameters for Logistic Regression\n",
    "param_grid_LogR = {'scaler' : scalers, \n",
    "                   'model' : [LogisticRegression()], \n",
    "                   'model__n_jobs': n_jobs}\n",
    "\n",
    "# Parameters for Principal Component Analysis\n",
    "param_grid_PCA = {'scaler' : scalers, \n",
    "                   'model' : [PCA()], \n",
    "                   'model__n_jobs': n_jobs}\n",
    "\n",
    "# Parameters for Support Vector Machines\n",
    "param_grid_SVM = {'scaler' : scalers, \n",
    "                   'model' : [LinearSVR()], \n",
    "                   'model__n_jobs': n_jobs}\n",
    "\n",
    "# Setting up the parameter grid as a list \n",
    "param_grids = [param_grid_LinR, \n",
    "               param_grid_LogR, \n",
    "               param_grid_PCA, \n",
    "               param_grid_SVM]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**: Finally, instantiate the Grid Search with 10 cross validations & fit on training set. \n",
    "\n",
    "The reason we choose 10 is because the data set is already pretty small so it might be of value to validate it with more cross validations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Setting up / Instantiating the gridsearch\n",
    "grid_model = GridSearchCV(estimator = pipeline,\n",
    "                          param_grid = param_grids,\n",
    "                          cv = 10,\n",
    "                          n_jobs = -1,\n",
    "                          verbose = 1)\n",
    "\n",
    "# Fitting the data on the grid\n",
    "grid_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for best parameters\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(grid_model.best_params_)\n",
    "print()\n",
    "\n",
    "# Checking for best score\n",
    "print()\n",
    "print(\"Grid best score:\")\n",
    "print (grid_model.best_score_)\n",
    "print()\n",
    "\n",
    "#Checking for best model\n",
    "print()\n",
    "print(\"Best model is:\")\n",
    "print(grid_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Talk about what some of the top factors are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
